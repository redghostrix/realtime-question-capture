# Real-Time Question Capture - Configuration Template
# Copy this file to .env and customize the values as needed
# Environment variables override these values

# ==================== Whisper Configuration ====================
# Model size: tiny, base, small, medium, large
# Larger models are more accurate but require more GPU memory
WHISPER_MODEL=base

# ==================== LLM Server Configuration ====================
# LLM server endpoint URL for question extraction
LLAMA_SERVER_URL=http://localhost:8080/v1/chat/completions

# Model identifier for question extraction
QUESTION_EXTRACTOR_MODEL_NAME=llama-3.3-70b-versatile

# Maximum number of retry attempts (0-10)
QUESTION_EXTRACTOR_MAX_RETRIES=3

# Request timeout in seconds (1-300)
QUESTION_EXTRACTOR_TIMEOUT=30

# ==================== Audio Capture Configuration ====================
# Audio sample rate in Hz (Whisper expects 16kHz)
# Valid range: 8000-48000
SAMPLE_RATE=16000

# Audio chunk duration in seconds (1-60)
# Smaller chunks = faster processing, less context
# Larger chunks = better context, slower processing
CHUNK_DURATION=5

# Number of audio channels: 1 (mono) or 2 (stereo)
CHANNELS=1

# ==================== Logging Configuration ====================
# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
